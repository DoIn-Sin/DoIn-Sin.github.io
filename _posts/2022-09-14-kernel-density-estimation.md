---
title: 커널밀도추정 톺아보기
description: 다시 시각화부터 살펴보다가 커널밀도추정에 대해 자세히 살펴봤습니다.
categories:
- Statistics
tags: 
- Statistics
---

예전에 처음 공부할 때 커널밀도추정 함수 그래프를 공부한 적이 있다. 그 때는 히스토그램을 부드럽게 이은 그래프라고 단순히 이해하고 넘어갔는데, 이제는 왜 그렇게 이해하면 되는지 알 필요가 있을 것 같아서 하나씩 뜯어봤다.

# Kernel Density Estimation(커널밀도추정)에 대한 이해
Kernel Density Estimation(KDE)란 커널함수(kernel function)를 이용한 밀도추정(density estimation) 방법의 하나로서 KDE를 알기 위해서는 먼저 밀도추정이 무엇인지 알 필요가 있다.

## 밀도추정(Density Estimation)
밀도추정은 관측된 데이터들의 분포로부터 원래 변수의 확률 분포 특성을 추정하고자 하는 것이다. 무슨 말일까? 조금 더 풀어서 말하면 데이터의 본질로 들어간다. 

데이터는 어떤 변수가 가질 수 있는 다양한 가능성 중의 하나가 현실 세계에 구체화된 값이다. 그리고 우리는 이렇게 관측된 데이터들을 통해 그 변수가 가지고 있는 본질적인 특성을 파악하고자 노력한다. 

그러나 하나의 데이터는 변수의 일면에 불과하기 때문에 변수의 진면목을 파악하기 위해서는 많은 수의 데이터가 필요하다. 이때 바로 밀도추정을 하는 것이다!

예를 들어, 어떤 육교밑을 통과하는 차량의 일일 교통량을 파악하는게 목적이라고 하자. 이 때의 변수는 '일일 교통량'이다. 그리고 실제 육교 위에서 매일 관찰한 값이 데이터이다.

어떤 날은 차가 500대가 지나가고, 어떤 날은 300대, 450대, ... 매일 서로 다른 데이터가 나올 수 있다. 하루, 이틀의 관측 결과만 가지고 이 육교의 '일일 교통량'이 무어라고 결론을 내리기는 힘들다.

하지만 이러한 데이터가 한달, 두달, 1년 넘게 쌓이게 되면 어떨까? 아마 그때는 '일일 교통량'이란 변수가 어떤 값의 분포를 갖는지 이전보다는 정확하게 파악할 수 있을 것이다.

지금처럼 어떤 변수가 가질 수 있는 값 및 그 값을 가질 가능성의 정도를 추정하는 것이 밀도 추정이다.

<br>

밀도는 수학적으로는 mass/volume으로 정의되만, 밀도 추정, 기계학습, 확률, 통계 등에서 말하는 밀도는 확률 밀도(probability)를 의미한다.

즉, 어떤 변수 x의 밀도를 추정하는 것은 x의 확률밀도함수(pdf, probability density function)를 추정하는 것과 동일한 말이다. 어떤 변수 x의 확률밀도함수 f(x)가 아래 그림과 같다고 하자.

![image](https://user-images.githubusercontent.com/77676907/189941050-d1b27187-1185-462e-bdac-8567efb5040e.png)

이 때, f(a)는 x = a에서의 확률밀도 즉, 변수 x가 a라는 값을 가질 상대적인 가능성을 나타낸다.

밀도와 확률을 구분해보면 위 그림에서 x = a일 확률은 0이지만, x = a에서의 밀도는 f(a)로 0이 아니다. 그리고 x가 a, b 사이의 값을 가질 확률은 그 구간에서의 확률밀도함수의 적분값(면적)으로 계산된다. 즉, 밀도는 확률밀도함수의 함수값이며 밀도를 일정 구간에 대해 적분하면 확률이 나온다.

어쨌든, 어떤 변수의 확률밀도함수(pdf)를 구할 수 있으면 그 변수가 가질 수 있는 값의 범위 및 확률분포, 특성을 모두 알수 있기 때문에 밀도추정은 확률, 통계, 기계학습, 파라미터 추정 등에서 가장 핵심적인 요소중의 하나이다.


## Parametric vs. Non-parametric 밀도추정

밀도추정(density estimation) 방법은 크게 parametric 방법과 non-parametric 방법으로 구분할 수 있다.



Parametric 밀도추정은 미리 pdf(probability density function)에 대한 모델을 정해놓고 데이터들로부터 모델의 파라미터만 추정하는 방식이다. 예를 들어, '일일 교통량'이 정규분포를 따른다고 가정해 버리면 관측된 데이터들로부터 평균과 분산만 구하면 되기 때문에 밀도추정 문제가 비교적 간단한 문제가 되어 버린다.



그런데 현실 문제에서 이렇게 모델이 미리 주어지는 경우는 많지 않으며 분포의 모델을 미리 안다는 것은 너무나 강한 혹은 사치스러운 가정일 수 있다. 이 경우 어떠한 사전 정보나 지식 없이 순수하게 관측된 데이터만으로 확률밀도함수를 추정해야 하는데 이를 non-parametric density estimation라 부른다.



Non-parametric 밀도추정의 가장 간단한 형태가 바로 히스토그램(histogram)이다. 즉, 관측된 데이터들로부터 히스토그램을 구한 후 구해진 히스토그램을 정규화하여 확률밀도함수로 사용하는 것이다.


## Kernel Density Estimation (커널 밀도 추정)
앞서 non-parametric 밀도추정의 가장 단순한 형태가 히스토그램(histogram) 방법이라고 했는데, 히스토그램 방법은 bin의 경계에서 불연속성이 나타난다는 점, bin의 크기 및 시작 위치에 따라서 히스토그램이 달라진다는 점, 고차원(high dimension) 데이터에는 메모리 문제 등으로 사용하기 힘들다는 점 등의 문제점을 갖는다.



Kernel Density Estimation (커널 밀도 추정) 방법은 non-parametric 밀도추정 방법 중 하나로서 커널함수(kernel function)를 이용하여 히스토그램 방법의 문제점을 개선한 방법이다.



먼저, 커널함수(kernel function)에 대한 이해가 필요한데 수학적으로 커널함수는 원점을 중심으로 대칭이면서 적분값이 1인 non-negative 함수로 정의되며 가우시언(Gaussian), Epanechnikov, uniform 함수 등이 대표적인 커널 함수들이다.

x를 변수(random variable), x1, x2, ..., xn을 관측된 샘플 데이터, K를 커널 함수라 하자. 이 때 KDE에서는 랜덤 변수 x에 대한 pdf(확률밀도함수)를 다음과 같이 추정한다.

![image](https://user-images.githubusercontent.com/77676907/189942605-40997fd7-5f29-40d2-9f21-1017f4dffdef.png)

위의 식에서 h는 커널(kernel) 함수의 bandwidth 파라미터로서 커널이 뽀족한 형태(h가 작은 값)인지 완만한 형태(h가 큰 값)인지를 조절하는 파라미터이다. 수식적으로 보면 어렵지만 이를 직관적으로 이해하면 다음과 같다.

>1. 관측된 데이터 각각마다 해당 데이터 값을 중심으로 하는 커널 함수를 생성한다: K(x-xi)
>2. 이렇게 만들어진 커널 함수들을 모두 더한 후 전체 데이터 개수로 나눈다.

## 히스토그램 vs 커널밀도추정 함수 그래프
히스토그램을 이용한 밀도추정 방법과 KDE 방법을 비교해 보면, 히스토그램 방법은 이산적(discrete)으로 각 데이터에 대응되는 bin의 값을 증가시킴으로써 불연속성이 발생하는 반면 KDE(커널밀도추정) 방법은 각 데이터를 커널 함수로 대치하여 더함으로써 아래 그림의 오른쪽 그래프와 같이 smooth한 확률밀도함수(pdf)를 얻을 수 있는 장점을 갖는다.

![image](https://user-images.githubusercontent.com/77676907/189943176-947d0b71-e420-4d2f-a01e-63eb39b1fde6.png)

즉, KDE(Kernel Density Estimation)를 통해 얻은 확률밀도함수는 히스토그램 확률밀도함수를 스무딩(smoothing)한 것으로도 볼 수 있으며 이 때, 스무딩(smoothing) 정도는 어떤 bandwidth 값의 커널 함수를 사용했으냐에 따라 달라진다.

실제 KDE를 사용할 때, 중요한 이슈는 어떤 커널 함수를 사용할지와 커널 함수의 bandwidth 파라미터인 h 값을 어떻게 잡을지이다. 위키피디아에 의하면 가장 최적의 커널함수는 Epanechnikov 커널이며 계산의 편의상 Gaussian 커널함수도 많이 사용된다고 한다. 그리고 Gaussian 커널함수를 사용할 경우 최적의 bandwidth 파라미터 값은 다음과 같다고 한다.

![image](https://user-images.githubusercontent.com/77676907/189943377-9eb4f4f4-64e6-4729-935d-100339c055c6.png)

>단, n은 샘플 데이터의 개수, σ는 샘플 데이터의 표준편차.